import os
import re
import csv
import git
import subprocess
from tqdm import tqdm

class DifyDatasetBuilder:
    def __init__(self, output_dir="dify_import_files"):
        self.output_dir = output_dir
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

    def save_to_csv(self, filename, rows, headers=["instruction", "output"]):
        """保存为 Dify 可识别的 CSV 格式"""
        filepath = os.path.join(self.output_dir, filename)
        with open(filepath, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(headers)
            writer.writerows(rows)
        print(f"Generated {filepath} with {len(rows)} entries.")

    # ------------------------------------------------------------------
    # 1. 处理 standard.h 和 standard.iso (基础定义)
    # ------------------------------------------------------------------
    def process_standard_files(self, standard_h_path, standard_iso_path):
        rows = []
        
        # 处理 standard.h
        if os.path.exists(standard_h_path):
            with open(standard_h_path, 'r', encoding='utf-8') as f:
                content = f.read()
            # 提取宏定义
            matches = re.findall(r'(#define\s+(\w+)\s*[^\n]*)', content)
            for full_line, name in matches:
                instruction = f"What is the standard macro '{name}' in Coccinelle?"
                output = f"In `standard.h`, the macro is defined as:\n```c\n{full_line.strip()}\n```\nIt helps ignore C-specific attributes during parsing."
                rows.append([instruction, output])

        # 处理 standard.iso
        if os.path.exists(standard_iso_path):
            with open(standard_iso_path, 'r', encoding='utf-8') as f:
                content = f.read()
            # 提取同构规则块
            # ISO 规则通常包含 "Expression" 或 "Statement" 关键字
            iso_blocks = re.split(r'\n\n(?=Expression|Statement|Type|Declaration)', content)
            for block in iso_blocks:
                name_match = re.search(r'@\s*([\w_]+)\s*@', block)
                if name_match:
                    name = name_match.group(1)
                    instruction = f"Coccinelle isomorphism rule for '{name}' (standard.iso)"
                    output = f"This rule handles code equivalence for '{name}'.\nDefinition:\n```\n{block.strip()}\n```"
                    rows.append([instruction, output])
        
        self.save_to_csv("cocci_standard_rules.csv", rows)

    # ------------------------------------------------------------------
    # 2. 处理 cocci_syntax.tex (转换为 Markdown 后分割)
    # ------------------------------------------------------------------
    def process_syntax_manual(self, tex_path):
        if not os.path.exists(tex_path):
            return
        
        # 调用 pandoc 将 tex 转为 markdown (纯文本更容易处理)
        try:
            md_content = subprocess.check_output(['pandoc', '-f', 'latex', '-t', 'markdown', tex_path]).decode('utf-8')
        except FileNotFoundError:
            print("Error: Pandoc not found. Please install pandoc.")
            return

        rows = []
        # 按二级标题切分 (# Header)
        sections = re.split(r'\n#+\s+', md_content)
        
        for sec in sections:
            lines = sec.split('\n')
            title = lines[0].strip()
            body = "\n".join(lines[1:]).strip()
            
            if len(body) > 20: # 忽略太短的段落
                instruction = f"Coccinelle Syntax Guide: {title}"
                output = f"### {title}\n{body}"
                rows.append([instruction, output])
                
        self.save_to_csv("cocci_syntax_manual.csv", rows)

    # ------------------------------------------------------------------
    # 3. 处理历史 Commit (挖掘意图和脚本)
    # ------------------------------------------------------------------
    def process_commits(self, repo_path, limit=500):
        try:
            repo = git.Repo(repo_path)
        except:
            print("Invalid git repo path")
            return

        rows = []
        keywords = ["Generated by", "Generated using", "semantic patch"]
        
        print("Mining commits...")
        commits = repo.iter_commits('master', max_count=limit, grep=keywords, regexp_ignore_case=True)
        
        for commit in tqdm(commits):
            msg = commit.message
            
            # 简单提取 Cocci 脚本 (寻找 @@ ... @@)
            script_match = re.search(r'(@@.*?@@.*)', msg, re.DOTALL)
            if not script_match:
                # 尝试找 embedded smpl
                script_match = re.search(r'//\s*<smpl>(.*?)//\s*</smpl>', msg, re.DOTALL)
            
            if script_match:
                script_content = script_match.group(1).strip()
                # 提取第一行作为 Intent
                summary = msg.split('\n')[0]
                
                instruction = f"Write a Coccinelle script to: {summary}"
                
                # 组合 Output：包含脚本和参考 Commit Hash
                output = f"""Reference Commit: {commit.hexsha}
Intent: {summary}

Coccinelle Script:
```cocci
{script_content}
```"""
                rows.append([instruction, output])

        self.save_to_csv("cocci_history_examples.csv", rows)

if __name__ == "__main__":
    builder = DifyDatasetBuilder()
    
    # 1. 设置路径 (请修改为你的实际路径)
    KERNEL_DIR = "/path/to/linux-stable"
    COCCI_SRC_DIR = "/path/to/coccinelle-source" # 包含 standard.h, standard.iso, docs/
    
    # 2. 生成规则库 CSV
    builder.process_standard_files(
        os.path.join(COCCI_SRC_DIR, "standard.h"),
        os.path.join(COCCI_SRC_DIR, "standard.iso")
    )
    
    # 3. 生成语法库 CSV
    builder.process_syntax_manual(
        os.path.join(COCCI_SRC_DIR, "docs/manual/cocci_syntax.tex")
    )
    
    # 4. 生成历史实例 CSV
    builder.process_commits(KERNEL_DIR, limit=500)